## 第1章 引言

Q: 1. (单选题, 5分)‏哪一个是机器学习的合理定义？ (            )

A: :机器学习能使计算机能够在没有明确编程的情况下学习;

------
Q: 2. (单选题, 5分)一个计算机程序从经验E中学习任务T，并用P来衡量表现。并且，T的表现P随着经验E的增加而提高。假设我们给一个学习算法输入了很多历史天气的数据，让它学会预测‏天气， (            ) 是P合理的选择。

A: :正确预测未来日期天气的概率;

------
Q: 3. (单选题, 5分)‌回归问题和分类问题的区别是什么？​ (            )

A: :回归问题输出值是连续的，分类问题输出值是离散的;

------
Q: 4. (单选题, 5分)‏以下关于特征选择的说法正确的是？​ (            )

A: :选择的特征需尽可能反映不同事物之间的差异;

------
Q: 5. (单选题, 5分)‏一个包含n类的多分类问题，若采用一对剩余的方法，需要拆分成多少次？ (            )

A: :n-1;

------
Q: 6. (单选题, 5分)​机器学习方法传统上可以分为 (            ) 类。

A: :3;

------
Q: 7. (单选题, 5分)‌哪些机器学习模型经过训练，能够根据其行为获得的奖励和反馈做出一系列决策？ (            )

A: :强化学习;

------
Q: 8. (单选题, 5分)‍机器学习这个术语是由 (            ) 定义的？

A: :Arthur Samuel;

------
Q: 9. (单选题, 5分)​哪种开发语言最适合机器学习？ (            ) ​

A: :Python;

------
Q: 10. (单选题, 5分)​ (            ) 是机器学习的一部分，与神经网络一起工作。​

A: :深度学习;

------
Q: 11. (单选题, 5分)‍ (            ) 是可用于标记数据的机器学习算法。​

A: :回归算法;

------
Q: 12. (单选题, 5分)‍谷歌新闻每天收集非常多的新闻，并运用 (            ) 方法再将这些新闻分组，组成若干类有关联的新闻。于是，搜索时同一组新闻事件往往隶属同一主题的，所以显示到一起。‏

A: :聚类;

------
Q: 13. (单选题, 5分)以下哪种技术对于减少数据集的维度会更好 (            )。

A: :删除缺少值太多的列;

------
Q: 14. (单选题, 5分)将原始数据进行集成、变换、维度规约、数值规约是在以下哪个步骤的任务？

A: :数据预处理;

------
Q: 15. (多选题, 5分)下列哪些学习问题不属于监督学习？ (            )

A: :聚类; 降维;

------
Q: 16. (多选题, 5分)‏‍下列哪些学习问题不属于监督学习？ (            ) ​

A: :聚类; 关联规则;

------
Q: 17. (多选题, 5分)‎机器学习的方法由 (            ) 等几个要素构成。

A: :模型; 损失函数; 优化算法; 模型评估指标;

------
Q: 18. (多选题, 5分)‌对于非概率模型而言，可按照判别函数线性与否分成线性模型与非线性模型。下面哪些模型属于线性模型？‏

A: :K-means; k近邻; 感知机;

------
Q: 19. (多选题, 5分)‎下面哪些是分类算法？

A: :根据肿瘤的体积、患者的年龄来判断良性或恶性？; 根据用户的年龄、职业、存款数量来判断信用卡是否会违约？; 身高 1.85m，体重 100kg 的男人穿什么尺码的 T 恤？;

------
Q: 20. (判断题, 5分)‎朴素贝叶斯属于概率模型。‎

A: 对

------
Q: 21. (判断题, 5分)‌根据肿瘤的体积、患者的年龄来判断良性或恶性，这是一个回归问题。

A: 错

------
Q: 22. (判断题, 5分)大部分的机器学习工程中，数据搜集、数据清洗、特征工程这三个步骤花了绝大部分时间，而数据建模，占总时间比较少。

A: 错

------
Q: 23. (判断题, 5分)‎已知你朋友的信息，比如经常发email的联系人，或是你微博的好友、微信的朋友圈，我们可运用聚类方法自动地给朋友进行分组，做到让每组里的人们彼此都熟识。‎

A: 对

------
Q: 24. (判断题, 5分)机器学习是一门涉及统计学、系统辨识、逼近理论、神经网络、优化理论、计算机科学、脑科学等诸多领域的交叉学科。


A: 对

------

## 第2章 回归

Q: 1. (单选题, 5分)‏ 以下哪组变量之间存在线性回归关系？‏ (            )

A: :正三角形的边长与周长;

------
Q: 2. (单选题, 5分)‏回归问题和分类问题的区别是？‏ (            )

A: :回归问题输出值是连续的，分类问题输出值是离散的;

------
Q: 3. (单选题, 5分)‌以下说法错误的是？​ (            )

A: :损失函数越小，模型训练得一定越好;

------
Q: 4. (单选题, 5分)‏哪些算法不需要数据归一化？ (            )

A: :决策树;

------
Q: 5. (单选题, 5分)‏以下哪些方法不能用于处理欠拟合？​ (            )

A: :增大正则化系数;

------
Q: 6. (单选题, 5分)‏以下哪些方法不能用于处理过拟合？‌ (            )

A: :增加数据属性的复杂度;

------
Q: 7. (单选题, 5分)‍下列关于线性回归分析中的残差（Residuals）说法正确的是？‏ (            )

A: :残差均值总是为零;

------
Q: 8. (单选题, 5分)‎为了观察测试 Y 与 X 之间的线性关系，X 是连续变量，使用下列哪种图形比较适合？‏ (            )

A: :散点图;

------
Q: 9. (单选题, 5分)‎假如你在训练一个线性回归模型，则：‎1. 如果数据量较少，容易发生过拟合。‎2. 如果假设空间较小，容易发生过拟合。‎关于这两句话，下列说法正确的是？ (            )

A: :1 正确，2 错误;

------
Q: 10. (单选题, 5分)​关于特征选择，下列对 Ridge 回归和 Lasso 回归说法正确的是？ (            )

A: :Lasso 回归适用于特征选择;

------
Q: 11. (单选题, 5分)‌构建一个最简单的线性回归模型需要几个系数（只有一个特征）？‍ (            )

A: :2个;

------
Q: 12. (单选题, 5分)‏向量x=[1, 2, 3, 4, -9, 0]的L1范数是多少？‌ (            )

A: :19;

------
Q: 13. (多选题, 5分)‌以下哪些是使用数据规范化(特征缩放)的原因？

A: :它不能防止梯度下降陷入局部最优; 它通过减少迭代次数来获得一个好的解，从而加快了梯度下降的速度;

------
Q: 14. (多选题, 5分)‎线性回归中，我们可以使用最小二乘法来求解系数，下列关于最小二乘法说法正确的是？ (            ) 。

A: :不需要迭代训练; 当特征数量很多的时候，运算速度会很慢; 只适用于线性模型，不适合逻辑回归模型等其他模型; 不需要选择学习率;

------
Q: 15. (多选题, 5分)‍欠拟合的处理主要有哪些方式：()

A: :添加新特征; 增加模型复杂度; 减小正则化系数;

------
Q: 16. (多选题, 5分)‎假如使用一个较复杂的回归模型来拟合样本数据，使用 Ridge回归，调试正则化参数，来降低模型复杂度，若正则化系数较大时，关于偏差(bias)和方差(variance)，下列说法正确的是？ (            ) 。

A: :方差减小; 偏差增大;

------

## 第3章 逻辑回归

Q: 1. (单选题, 5分)‌一监狱人脸识别准入系统用来识别待进入人员的身份，此系统一共包括识别4种不同的人员：狱警，小偷，送餐员，其他。下面哪种学习方法最适合此种应用需求：‏ (            )

A: :多分类问题;

------
Q: 2. (单选题, 5分)‏以下关于分类问题的说法错误的是？ (            ) 。

A: :分类问题输入属性必须是离散的;

------
Q: 3. (单选题, 5分)​以下关于逻辑回归与线性回归问题的描述错误的是 (            ) 。

A: :线性回归要求输入输出值呈线性关系，逻辑回归不要求;

------
Q: 4. (单选题, 5分)‌以下关于sigmoid函数的优点说法错误的是？‏ (            )

A: :在深层次神经网络反馈传输中，不易出现梯度消失;

------
Q: 5. (单选题, 5分)‏逻辑回归的损失函数是哪个？​ (            )

A: :交叉熵(Cross-Entropy)损失函数;

------
Q: 6. (单选题, 5分)‌下面哪一项不是Sigmoid的特点？ (            )

A: :当σ(z)小于0.5时，预测 y=-1;

------
Q: 7. (单选题, 5分)‍下列哪一项不是逻辑回归的优点？ (            )

A: :处理非线性数据较容易;

------
Q: 8. (单选题, 5分)‏假设有三类数据，用OVR方法需要分类几次才能完成？ (            )

A: :2;

------
Q: 9. (单选题, 5分)‏以下哪些不是二分类问题？‏ (            )

A: :身高1.85m，体重100kg的男人穿什么尺码的T恤？;

------
Q: 10. (单选题, 5分)​逻辑回归通常采用哪种正则化方式？ (            )

A: :L2正则化;

------
Q: 11. (单选题, 5分)‍假设使用逻辑回归进行多类别分类，使用 OVR 分类法。下列说法正确的是？‏ (            )

A: :对于 n 类别，需要训练 n 个模型;

------
Q: 12. (单选题, 5分)​你正在训练一个分类逻辑回归模型。以下哪项陈述是正确的？ (            )

A: :向模型中添加新特征总是会在训练集上获得相同或更好的性能;

------
Q: 13. (单选题, 5分)在逻辑回归中，如果同时加入 L1 和 L2 范数，不会产生什么效果‌ (            )？

A: :可以获得更准确的结果;

------
Q: 14. (多选题, 5分)‎以下哪项陈述是正确的？选出所有正确项 (            ) 。

A: :如果您的模型拟合训练集，那么获取更多数据可能会有帮助。; 使用一个非常大的训练集使得模型不太可能过拟合训练数据。; 逻辑回归使用了Sigmoid激活函数;

------
Q: 15. (多选题, 5分)‌下面哪些是分类算法？

A: :根据用户的年龄、职业、存款数量来判断信用卡是否会违约？; 根据肿瘤的体积、患者的年龄来判断良性或恶性？; 身高1.85m，体重100kg的男人穿什么尺码的T恤？;

------

## 第4章 朴素贝叶斯

Q: 1. (单选题, 5分)‌假设会开车的本科生比例是15%，会开车的研究生比例是23%。若在某大学研究生占学生比例是20%，则会开车的学生是研究生的概率是多少？ (            )

A: :27.70%;

------
Q: 2. (单选题, 5分)‏下列关于朴素贝叶斯的特点说法错误的是 (            ) 。

A: :朴素贝叶斯模型无需假设特征条件独立;

------
Q: 3. (单选题, 5分)‎以下算法不属于生成模型 (            ) 。

A: :支持向量机;

------
Q: 4. (单选题, 5分)‌关于拉普拉斯平滑说法正确的是 (            ) ​

A: :避免了出现概率为0的情况;

------
Q: 5. (单选题, 5分)​假设X和Y都服从正态分布，那么P(X<5,Y<0)就是一个 (            ) ，表示X<5,Y<0两个条件同时成立的概率，即两个事件共同发生的概率。

A: :联合概率;

------
Q: 6. (单选题, 5分)‏以下算法属于判别模型的是 (            ) 。

A: :线性回归;

------
Q: 7. (单选题, 5分)‏朴素贝叶斯的优点不包括 (            ) 。

A: :朴素贝叶斯模型对输入数据的表达形式很敏感;

------
Q: 8. (单选题, 5分)‏市场上某商品来自两个工厂，它们市场占有率分别为60%和40%，有两人各自买一件，则买到的来自不同工厂之概率为 (            ) 。

A: :0.48;

------
Q: 9. (单选题, 5分)‌以A表示事件"甲种产品畅销，乙种产品滞销"，则其对立事件A为 (            ) 。

A: :甲种产品滞销或乙种产品畅销;

------
Q: 10. (单选题, 5分)‏ 关于朴素贝叶斯，下列说法错误的是： (            )

A: :朴素贝叶斯不需要使用联合概率;

------
Q: 11. (单选题, 5分)掷二枚骰子，事件A为出现的点数之和等于3的概率为 (            ) ‏

A: :1/18;

------
Q: 12. (单选题, 5分)‍公司里有一个人穿了运动鞋，推测是男还是女？已知公司里男性30人，女性70人，男性穿运动鞋的有25人，穿拖鞋的有5人，女性穿运动鞋的有40人，穿高跟鞋的有30人。则以下哪项计算错误 (            ) ？‏

A: :P(运动鞋｜女性)=0.4;

------
Q: 13. (单选题, 5分)‌ 假设会开车的本科生比例是 15%，会开车的研究生比例是 23%。若在某大学研究生占学生比例是 20%，则会开车的学生是研究生的概率是多少？

A: :27.71%;

------

## 第5章 机器学习实践

Q: 1. (单选题, 5分)‌以下关于训练集、验证集和测试集说法不正确的是 (            ) 。

A: :训练集是用来训练以及评估模型性能;

------
Q: 2. (单选题, 5分)‌当数据分布不平衡时，我们可采取的措施不包括 (            ) 。‏

A: :对数据分布较多的类别赋予更大的权重;

------
Q: 3. (单选题, 5分)‍假设有100张照片，其中，猫的照片有60张，狗的照片是40张。‍识别结果：TP=40，FN=20，FP=10，TN=30，则可以得到： (            ) 。‎

A: :Precision=0.8;

------
Q: 4. (单选题, 5分)‍关于数据规范化，下列说法中错误的是 (            ) 。

A: :标准化在任何场景下受异常值的影响都很小;

------
Q: 5. (单选题, 5分)‎下列哪种方法可以用来缓解过拟合的产生： (            ) 。‏

A: :正则化;

------
Q: 6. (单选题, 5分)‎以下关于ROC和PR曲线说法不正确的是 (            ) 。‎

A: :类别不平衡问题中，ROC曲线比PR曲线估计效果要差;

------
Q: 7. (单选题, 5分)‍以下关于偏差(Bias)和方差(Variance)说法正确的是 (            ) 。‏

A: :获取更多的训练数据可解决高方差的问题;

------
Q: 8. (单选题, 5分)‏关于L1正则化和L2正则化说法错误的是 (            ) 。‏

A: :L1正则化比L2正则化使用更广泛;

------
Q: 9. (单选题, 5分)‏随着训练样本的数量越来越大，则该数据训练的模型将具有： (            ) 。

A: :低方差;

------
Q: 10. (单选题, 5分)‏随着训练样本的数量越来越大，则该数据训练的模型将具有： (            ) 。​

A: :相同偏差;

------
Q: 11. (单选题, 5分)​关于特征选择，下列对Ridge回归和Lasso回归的说法正确的是： (            ) 。​

A: :Lasso回归适用于特征选择;

------
Q: 12. (单选题, 5分)‌一个正负样本不平衡问题(正样本99%，负样本 1%)。假如在这个非平衡的数据集上建立一个模型，得到训练样本的正确率是 99%，则下列说法正确的是？ (            ) 。

A: :模型正确率并不能反映模型的真实效果;

------
Q: 13. (多选题, 5分)‎以下关于交叉验证说法正确的是 (            ) 。

A: :交叉验证可对模型性能合理评估; 交叉验证可利用模型选择避免过拟合的情况; 交叉验证大大增加了计算量;

------
Q: 14. (多选题, 5分)‍评价指标中，精确率(Precision)的计算需要哪些数值 (            ) 。

A: :TP; FP;

------
Q: 15. (多选题, 5分)‌评价指标中，召回率(Recall)的计算需要哪些数值 (            ) 。

A: :TP; FN;

------
Q: 16. (多选题, 5分)‏评估完模型之后，发现模型存在高偏差(high bias)，应该如何解决？ (            ) ‏

A: :增加模型的特征数量; 尝试减少正则化系数;

------
Q: 17. (多选题, 5分)‎ 以下哪些是使用数据规范化(特征缩放)的原因？

A: :它通过减少迭代次数来获得一个好的解，从而加快了梯度下降的速度; 它不能防止梯度下降陷入局部最优;

------

## 第7章 决策树

Q: 1. (单选题, 5分)‌以下关于决策树特点分析的说法错误的有 (            ) 。

A: :算法考虑了数据属性之间的相关性;

------
Q: 2. (单选题, 5分)‌以下关于决策树原理介绍错误的有 (            ) 。

A: :决策树算法属于无监督学习;

------
Q: 3. (单选题, 5分)​我们想要在大数据集上训练决策树模型，为了使用较少的时间，可以： (            ) 。‎

A: :减少树的深度;

------
Q: 4. (单选题, 5分)‍以下关于决策树算法说法错误的是 (            ) 。

A: :C4.5算法不能用于处理不完整数据;

------
Q: 5. (单选题, 5分)​以下关于剪枝操作说法正确的是 (            ) 。​

A: :ID3没有剪枝策略;

------
Q: 6. (单选题, 5分)‏C4.5选择属性用的是 (            ) 。‏

A: :信息增益率;

------
Q: 7. (单选题, 5分)‎哪种决策树没有剪枝操作 (            ) 。‎

A: :ID3;

------
Q: 8. (单选题, 5分)‌以下那种说法是错误的 (            ) 。‎

A: :中国足球队战胜巴西足球队的信息熵要小于中国乒乓球队战胜巴西乒乓球队的信息熵;

------
Q: 9. (单选题, 5分)​ID3 算法的缺点不包括 (            ) 。​

A: :既能用于处理离散分布的特征，也能用于连续分布的特征处理;

------
Q: 10. (单选题, 5分)‍关于CART算法，错误的是 (            ) 。

A: :CART算法采用信息增益率的大小来度量特征的各个划分点;

------
Q: 11. (单选题, 5分)‍关于C4.5算法，错误的是 (            ) 。

A: :C4.5算法采用基尼系数的大小来度量特征的各个划分点;

------
Q: 12. (单选题, 5分)‌ID3选择属性用的是 (            ) 。

A: :信息增益;

------
Q: 13. (多选题, 5分)‌决策树有哪些代表算法 (            ) 。

A: :CART; ID3; C4.5;

------
Q: 14. (多选题, 5分)‌以下那种算法需要对数据进行归一化或者标准化 (            ) 。

A: :KNN; 逻辑回归; 线性回归;

------
Q: 15. (多选题, 5分)‎关于剪枝，以下算法正确的是： (            ) 。

A: :ID3算法没有剪枝操作; 剪枝是防止过拟合的手段; 决策树剪枝的基本策略有预剪枝和后剪枝;

------
Q: 16. (多选题, 5分)‎决策树的说法正确的是 (            ) 。‎

A: :其可作为分类算法，也可用于回归模型; 它易于理解、可解释性强; CART使用的是二叉树;

------
Q: 17. (判断题, 5分)‏ID3 算法的核心思想就是以信息增益来度量特征选择，选择信息增益最大的特征进行分裂。‎

A: 对

------
Q: 18. (判断题, 5分)‌C4.5是通过代价复杂度剪枝。

A: 错

------
Q: 19. (判断题, 5分)‌ID3 算法只能用于处理离散分布的特征。‎

A: 对

------
Q: 20. (判断题, 5分)​ID3和C4.5和CART都只能用于分类问题，不能用于回归问题。

A: 错

------

## 第8章 集成学习

Q: 1. (单选题, 5分)‏在随机森林里，你生成了几百颗树(T1, T2 …..Tn)，然后对这些树的结果进行综合，下面关于随机森林中每颗树的说法正确的是？ (            ) 。

A: :每棵树是通过数据集的子集和特征的子集构建的;

------
Q: 2. (单选题, 5分)‎以下关于集成学习特性说法错误的是 (            ) 。‎

A: :集成多个线性分类器也无法解决非线性分类问题;

------
Q: 3. (单选题, 5分)‌以下关于随机森林(Random Forest)说法正确的是 (            ) 。​

A: :随机森林学习过程分为选择样本、选择特征、构建决策树、投票四个部分;

------
Q: 4. (单选题, 5分)​以下关于AdaBoost算法说法正确的是 (            ) 。‏

A: :AdaBoost使用的损失函数是指数函数;

------
Q: 5. (单选题, 5分)‍以下关于GBDT算法说法错误的是 (            ) 。‏

A: :GBDT使用的是放回采样;

------
Q: 6. (单选题, 5分)‏XGBoost算法说法错误的是 (            ) 。

A: :XGBoost算法要求对数据进行归一化或者标准化;

------
Q: 7. (单选题, 5分)‌关于Bagging方法，以下说法错误的是 (            )

A: :对各弱分类器的训练可以通过串行方式进行;

------
Q: 8. (单选题, 5分)‏Adboost的优点不包括 (            ) 。

A: :对异常点敏感，异常点会获得较高权重;

------
Q: 9. (单选题, 5分)‍LightGBM与XGBoost相比，主要的优势不包括 (            ) 。‎

A: :采用二阶泰勒展开加快收敛;

------
Q: 10. (单选题, 5分)‍以下关于随机森林和GBDT的描述不正确的是 (            ) 。( )​

A: :两者都是使用了Boosting思想;

------
Q: 11. (单选题, 5分)‎以下那种算法不是集成学习算法 (            ) 。

A: :决策树;

------
Q: 12. (单选题, 5分)‎关于GBDT算法的描述，不正确的是 (            ) 。‏

A: :梯度提升算法通过迭代地选择一个梯度方向上的基函数来逐渐逼近局部极小值;

------
Q: 13. (单选题, 5分)数据科学家可能会同时使用多个算法（模型）进行预测，并且最后把这些算法的结果集成起来进行最后的预测（集成学习），以下对集成学习说法正确的是 (            ) 。‍

A: :单个模型之间有低相关性;

------
Q: 14. (单选题, 5分)‍Bootstrap 数据的含义是‏ (            ) 。‍

A: :有放回的从整体 N 中抽样 n 个样本;

------
Q: 15. (单选题, 5分)假设有 6 个二维数据点：D={(2, 3), (5, 7), (9, 6), (4, 5), (6, 4)，(7, 2)}，第一次切分时候，切分线为 (            ) 。‍

A: :x=6;

------
Q: 16. (多选题, 5分)​集成学习有以下哪几种代表算法 (多选) (            ) 。‎

A: :AdaBoost; 随机森林;

------
Q: 17. (多选题, 5分)‍下面关于随机森林和梯度提升集成方法的说法哪个是正确的？ (            ) ‏

A: :两种方法都可以用来做回归; 这两种方法都可以用来做分类;

------
Q: 18. (多选题, 5分)‎LightGBM与XGBoost相比，主要有以下几个改进：(多选) (            ) 。

A: :互斥特征捆绑算法(Exclusive Feature Bundling, EFB); 直方图算法(Histogram); 基于梯度的单边采样算法(Gradient-based One-Side Sampling, GOSS); 基于最大深度的 Leaf-wise 的垂直生长算法;

------
Q: 19. (多选题, 5分)‌GBDT由哪三个概念组成： (            ) 。

A: :Shrinkage(缩减); Regression Decision Tree(即 DT); Gradient Boosting(即 GB);

------
Q: 20. (判断题, 5分)‌XGBoost对损失函数做了二阶泰勒展开，GBDT只用了一阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶、二阶可导。​

A: 对

------
Q: 21. (判断题, 5分)‏集成学习的数据不需要归一化或者标准化。​

A: 对

------
Q: 22. (判断题, 5分)LightGBM在建树过程中，采用基于最大深度的 Leaf-wise 的垂直生长算法。​‎

A: 对

------
Q: 23. (判断题, 5分)随机森林和GBDT都是使用了Bagging思想。​‎

A: 错

------

## 第10章 支持向量机

Q: 1. (单选题, 5分)‍对于在原空间中线性不可分问题，支持向量机 (            ) 。‎

A: :将数据映射到核空间中;

------
Q: 2. (单选题, 5分)​关于支持向量机中硬间隔和软间隔的说法错误的是 (            ) 。

A: :硬间隔有利于消除模型的过拟合;

------
Q: 3. (单选题, 5分)‍关于各类核函数的优缺点说法错误的是： (            ) 。​

A: :高斯核计算简单，不容易过拟合;

------
Q: 4. (单选题, 5分)‍如果一个样本空间线性可分，那么,我们能找到 (            ) 个平面来划分样本。

A: :无数;

------
Q: 5. (单选题, 5分)‍SVM算法的最小时间复杂度是O(n^2)。基于这一点，以下哪种规格的数据集并不适用于该算法？ (            ) 。

A: :大数据集;

------
Q: 6. (单选题, 5分)‎线性SVM和一般线性分类器的区别主要是： (            ) 。‏

A: :是否确保间隔最大化;

------
Q: 7. (单选题, 5分)‌在SVM中, margin的含义是 (            ) 。

A: :间隔;

------
Q: 8. (单选题, 5分)‍SVM算法的性能取决于： (            ) 。

A: :以上所有;

------
Q: 9. (单选题, 5分)​SVM中的代价参数C表示什么？ (            ) 。​

A: :在分类准确性和模型复杂度之间的权衡;

------
Q: 10. (单选题, 5分)‍一个正例(2,3)，一个负例(0,-1)，下面哪个是SVM超平面？ (            ) 。

A: :.x+2y-3=0;

------
Q: 11. (单选题, 5分)‌SVM 原理描述不正确的是 (            ) 。

A: :SVM 的基本模型是在特征空间中寻找间隔最小化的分离超平面的线性分类器;

------
Q: 12. (单选题, 5分)‍SVM普遍使用的准则描述不正确的是： (            ) (n为特征数，m为训练样本数。)

A: :支持向量机理论上不能处理太多的特征。;

------
Q: 13. (单选题, 5分)下列不是 SVM 核函数的是 (            )

A: :逻辑核函数;

------
Q: 14. (多选题, 5分)​以下关于支持向量机的说法正确的是 (            ) 。‏

A: :SVM分类面取决于支持向量; SVM方法简单，鲁棒性较好;

------
Q: 15. (多选题, 5分)‌支持向量机有哪些常用的核函数 (            ) 。

A: :线性核; 多项式核; 高斯核;

------
Q: 16. (多选题, 5分)‍下面关于支持向量机的描述正确的是 (            ) 。

A: :是一种监督学习的方法; 支持非线性的核函数; 可用于多分类的问题;

------
Q: 17. (多选题, 5分)‏关于SVM的描述正确的是： (            ) ‏

A: :支持向量机的学习策略就是间隔最大化; 支持向量机可以通过核技巧，这使之成为实质上的非线性分类器; 支持向量机模型定义在特征空间上的间隔最大的线性分类器;

------
Q: 18. (判断题, 5分)SVM是这样一个分类器，他寻找具有最小边缘的超平面，因此它也经常被称为最小间隔分类器(minimal margin classifier) 。

A: 错

------
Q: 19. (判断题, 5分)‍SVM的数据需要归一化或者标准化。

A: 对

------
Q: 20. (判断题, 5分)​支持向量是最靠近决策表面的数据点。​

A: 对

------
Q: 21. (判断题, 5分)SVM中核函数将高维空间中的数据映射到低维空间。

A: 错

------
